---
title: "R Notebook"
output: 
  html_document:
    keep_md: true
---

## Análise exploratória microdados ENEM 2016
```{r}
require(data.table)
require(dplyr)
require(caret)
require(ggplot2)
require(broom)
require(tidyr)
require(corrplot)
require(nortest)
require(forcats)
require(mlbench)
```


Iniciamos lendo a base de dados.
```{r}
dados = fread("C:/Users/Mateus/Desktop/Microdados_Enem_2016.csv", sep = ",", encoding = "UTF-8", na.strings = "")
```

```{r}
dim(dados)
```
A base contém 13730 linhas e 167 colunas.
```{r}
# verifying column classes
sapply(dados, class)
```

Verificando a classe das colunas, nota-se que muitos indicadores estão sendo lidos como numéricos. Devem ser lidos como um caractere. Adiciona-se aos dados faltantes, a palavra "missing", visto que é também um nível e sua análise é de suma importância.
```{r}
# transforming features to character
dados = dados %>% mutate_at(vars(starts_with("Q0")), list(~as.character))
dados = dados %>% mutate_at(vars(starts_with("TP")), list(~as.character))
dados = dados %>% mutate_at(vars(starts_with("IN")), list(~as.character))

# counting NA cells for each column
sapply(dados, function(x) sum(is.na(x)))

# adding to NA cells for character columns the word "missing"
na_to_space <- function(x) ifelse(is.na(x),"missing",x)
dados = dados %>% mutate_if(is.character, na_to_space) 
```
Nota-se que não há nenhum dado faltante na base agora.

```{r}
numeric_var = dados %>% select(starts_with("NU_")); numeric_var = numeric_var %>% select(-c(NU_INSCRICAO, NU_ANO))
# selecting all variables that are "TP"
catego_var_tp = dados %>% select(starts_with("TP_"))
catego_var_sg = dados %>% select(starts_with("SG_"))
catego_var = bind_cols(catego_var_sg, catego_var_tp)
```

```{r}
distributions = numeric_var %>% gather() %>% 
                                ggplot(aes(x = value, fill = key)) +  
                                scale_fill_brewer(palette="Spectral") +
                                facet_wrap(~ key, scales = "free") +
                                geom_density(alpha = 0.4) + 
                                labs(title = "Figura 1: Densidade de probabilidade para todas as variáveis numéricas", 
                                     x = "escala da variável", y = "densidade", caption = "Fonte: microdados ENEM 2016") +
                                theme(legend.position = "none")
distributions
```

```{r}
dist.categ = catego_var_sg %>% gather() %>% 
                             ggplot(aes(x = value, fill = key)) +  
                             facet_grid(key ~. , scales = "free") +
                             geom_bar(alpha = 0.4) +
                             labs(title = "Figura 2: Distribuição para todas as variáveis com siglas", 
                                  x = "escala da variável", y = "densidade", caption = "Fonte: microdados ENEM 2016") +
                             theme(legend.position = "none")

dist.categ
```

```{r}
dist.categ.tp = catego_var_tp %>% gather() %>% 
                                  ggplot(aes(x = value, fill = key)) +  
                                  facet_wrap(~key, scales = "free") +
                                  geom_bar(alpha = 0.4) +
                                  labs(title = "Figura 3: Distribuição para todas as variáveis com TP", 
                                       x = "escala da variável", y = "densidade", caption = "Fonte: microdados ENEM 2016") +
                                  theme(legend.position = "none")

dist.categ.tp
```

Pela porcentagem de todas as classes de atendimento especializado serem muito baixas, preferiu-se criar um gráfico que evidencia apenas as classes que possuem esse tipo de atendimento.
```{r}
#selecting all variables that are indicators
indic_var = dados %>% select(starts_with("IN_")) %>% mutate_all(as.factor)

# summarizing percentage of special attendance
summ.spec.attend = indic_var[,2:14] %>% gather() %>% 
                   dplyr::group_by(key, value) %>% dplyr::summarise(n = n()) %>%
                   dplyr::mutate(perc = n / sum(n)) %>% select(-n) %>% filter(value == 1) %>% arrange(perc)

spec.attend = summ.spec.attend %>%
  ggplot() +  
  geom_bar(aes(x = reorder(key,-perc), y = perc), stat = "identity") + coord_flip() +
  labs(title = "Figura 4: Percentual de atendimentos especializados", subtitle = "(em relação a todos estudantes inscritos)",
       x = "tipo de atendimento especializado", y = "percentual de todos estudantes inscritos", caption = "Fonte: microdados ENEM 2016") +
  theme(legend.position = "none")

spec.attend
```
```{r}
summ.specific.attend = indic_var[,15:19] %>% gather() %>% 
  dplyr::group_by(key, value) %>% dplyr::summarise(n = n()) %>%
  dplyr::mutate(perc = n / sum(n)) %>% select(-n) %>% filter(value == 1) %>% arrange(perc)

spec.specific = summ.specific.attend %>%
  ggplot() +  
  geom_bar(aes(x = reorder(key,-perc), y = perc), stat = "identity") + coord_flip() +
  labs(title = "Figura 5: Percentual de atendimento específico", subtitle = "(em relação a todos estudantes inscritos)",
       x = "tipo de atendimento especifico", y = "percentual de todos estudantes inscritos") +
  theme(legend.position = "none")

spec.specific
```

```{r}
summ.resources.attend = indic_var[,20:53] %>% gather() %>% 
  dplyr::group_by(key, value) %>% dplyr::summarise(n = n()) %>%
  dplyr::mutate(perc = n / sum(n)) %>% select(-n) %>% filter(value == 1) %>% arrange(perc)

spec.resources = summ.resources.attend %>%
  ggplot() +  
  geom_bar(aes(x = reorder(key,-perc), y = perc), stat = "identity") + coord_flip() +
  labs(title = "Figura 6: Percentual de recursos especializados", subtitle = "(em relação a todos estudantes inscritos)", 
       x = "tipo de recursos especializados", y = "percentual de todos estudantes inscritos") +
  theme(legend.position = "none")

spec.resources
```
Verifica-se que o recurso especializado mais utilizado é 

Na imagem abaixo, vemos a porcentagem de todos os alunos que residem em algum estado e o faz em outro estado. lê-se o heat map por "linha", as quais somam-se 100%. 
```{r}
resid.vs.prova = data.frame(prop.table(table(dados$SG_UF_RESIDENCIA, dados$SG_UF_PROVA),1)) %>% 
                 rename("uf_residencia" = "Var1", "uf_prova" = "Var2", "percentual" = "Freq") %>% 
                 filter(!uf_residencia == uf_prova)

ggplot(data = resid.vs.prova, aes(x=uf_residencia, y=uf_prova, fill=percentual)) + 
  geom_tile() + coord_flip() + labs(title = "Figura 7: Percentual de estudantes incritos que residem em um estado", subtitle = "e fizeram a prova em   outro, por estado", caption = "Fonte: microdados ENEM 2016")
```

A diagonal principal da matriz foi retirada para dar ênfase nos pequenos percentuais que são as trocas de estado para se fazer a prova.
Nota-se, por exemplo, que 2,56% dos alunos que residem em SC fizeram a prova em RS. nota-se, também, que basicamente todos os residentes em RR e RO fizeram a prova em seus estados de residência.

```{r}
dados = dados %>% mutate(SG_UF_NASCIMENTO = ifelse(SG_UF_NASCIMENTO == "missing", NA, SG_UF_NASCIMENTO))
nasc.vs.resid = data.frame(prop.table(table(dados$SG_UF_NASCIMENTO, dados$SG_UF_RESIDENCIA),1)) %>% 
                            rename("uf_nascimento" = "Var1", "uf_residencia" = "Var2", "percentual" = "Freq") %>% 
                            filter(!uf_nascimento == uf_residencia)

ggplot(data = nasc.vs.resid, aes(x=uf_nascimento, y=uf_residencia, fill=percentual)) + 
  geom_tile() + coord_flip() + labs(title = "Figura 8: Percentual de estudantes incritos que nasceram em um estado", subitle = "e residem em outro, por estado",  caption = "Fonte: microdados ENEM 2016")
```
A diagonal principal da matriz foi retirada para dar ênfase nos pequenos percentuais que são as trocas de estado para se residir.
Nota-se, por exemplo, que 17,04% dos alunos que nasceram em DF moram em GO. justifica-se, provavelmente, por DF ser a menor unidade federativa do país, sendo rodeada por outras cidades que utilizam suas estruturas.
Nota-se, também, que basicamente todos os residentes em RR e RO fizeram a prova em seus estados de residência.

Aplicando a todas as colunas numéricas (NU_) teste de normalidade: utilizando teste Anderson-Darling porque Shapiro-Wilk não é permitido para >5000 linhas.
```{r, warning=FALSE}
x = sapply(numeric_var, ad.test)
tidy(x)[2,2:ncol(tidy(x))] %>% gather()
```

Todos resultados foram significativos a 5% de significância, confirmando que nenhuma distribuição segue normalidade
Por isso, a correlação a ser utilizada é a de Spearman.

```{r, results = FALSE, warning = FALSE}
# function to create p-value for pearson correlation                      
cor.mtest <- function(mat, ...) {
  mat <- as.matrix(mat)
  n <- ncol(mat)
  p.mat<- matrix(NA, n, n)
  diag(p.mat) <- 0
  for (i in 1:(n - 1)) {
    for (j in (i + 1):n) {
      tmp <- cor.test(mat[, i], mat[, j], method = "spearman")
      p.mat[i, j] <- p.mat[j, i] <- tmp$p.value
    }
  }
  colnames(p.mat) <- rownames(p.mat) <- colnames(mat)
  p.mat
}

# matrix with p-values of the correlations (calling 'cor.mtest' function above)
p.mat <- cor.mtest(numeric_var)

# calculating pearson correlation between all numeric variables (and removing rows that contain NA)
M.spearman = cor(na.omit(numeric_var), method = "spearman")

# applying colors to plot
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))

corrplot(M.spearman, method="color", col=col(200),  
         type="upper", order="hclust", 
         addCoef.col = "black", # Add coefficient of correlation
         tl.col="black", tl.srt=45, #Text label color and rotation
         # Combine with significance (5%)
         p.mat = p.mat, sig.level = 0.05, insig = "blank", 
         # hide correlation coefficient on the principal diagonal
         diag=FALSE)
```

Das competências da redação (NU_NOTA_COMP1:NU_NOTA_COMP5), todas as correlações são altas com a nota final da redação (NU_NOTA_REDACAO), 

# TESTES DE HIPÓTESE

Há diferenças significativas das notas em sexos diferentes? Em raças diferentes?

Visto que as varíáveis numéricas não provém de uma distribuição normal (a partir do teste Anderson Darling), compara-se as médias do grupo através de técnicas não paramétricas. Ao se plotar a distribuição das variáveis, as mesmas parecem seguir normalidade, mas, quando o teste é realizado sobre a amostra, rejeita-se a hipótese nula (provém de uma distribuição normal) pelo alto poder do teste. Como a amostra também é grande, isso influencia a rejeitar a hipótese nula também.
Utiliza-se, portanto, o teste de Mann-Whitney para averiguar se duas amostras independentes foram retiradas de
populações com médias iguais.

```{r}
dados %>% group_by(TP_SEXO) %>% dplyr::summarise(MEDIA_REDACAO = mean(NU_NOTA_REDACAO, na.rm = TRUE))
ggplot(dados, aes_string(x = "NU_NOTA_REDACAO", color = "TP_SEXO", fill = "TP_SEXO")) + 
                         geom_density(alpha = 0.3)
dados %>% group_by(TP_SEXO) %>%
          dplyr::summarise(statistic = ad.test(NU_NOTA_REDACAO)$statistic,
                    p.value = ad.test(NU_NOTA_REDACAO)$p.value) 
```
Nota-se que o valor p é < 0.05, tornando o teste significativo e rejeitando a hipótese nula (as amostras foram retiradas de populações com médias iguais). 
Conclui-se que há diferença significativa (ao nível de 5% de significância) de nota de redação para sexos diferentes.

```{r}
dados %>% group_by(TP_COR_RACA) %>% dplyr::summarise(MEDIA_REDACAO = mean(NU_NOTA_REDACAO, na.rm = TRUE))
ggplot(dados, aes_string(x = "NU_NOTA_REDACAO", color = "TP_COR_RACA", fill = "TP_COR_RACA")) + 
  geom_density(alpha = 0.3)
kruskal.test(NU_NOTA_REDACAO ~ TP_COR_RACA, data = dados)
```
O teste mostra que há uma diferença (ou diferenças) significativa(s) entre as MEDIANAS do grupo de seis amostras.

```{r}
dados %>% group_by(Q006) %>% dplyr::summarise(MEDIA_REDACAO = mean(NU_NOTA_REDACAO, na.rm = TRUE))
ggplot(dados, aes_string(x = "NU_NOTA_REDACAO", color = "Q006", fill = "Q006")) + 
  geom_density(alpha = 0.3)
kruskal.test(NU_NOTA_REDACAO ~ Q006, data = dados)
```
Pelo gráfico e teste, confirma-se que quanto maior a renda, maior a nota da redação.
Há diferença significativa de mediana de notas de redação entre pelo menos dois grupo de renda.

# SEGMENTATION

```{r}
#########################
# STUDENTS SEGMENTATION #
#########################

# filtering students that effectively took all the tests (4 tests: CH > natural sciences; CH > human sciences; LC > languages; MT > math)
segment.db = dados %>% filter(TP_PRESENCA_CH == 1 & TP_PRESENCA_CN == 1 & TP_PRESENCA_LC == 1 & TP_PRESENCA_MT == 1) %>% 
                       select(-c(starts_with("CO_"), starts_with("TX_"), starts_with("NO_MUNICIPIO"), V1, NU_INSCRICAO, NU_ANO, NO_ENTIDADE_CERTIFICACAO))
nrow(segment.db) # rows from filtered database
nrow(segment.db) / nrow(dados) # percentage of filtered database comparing to full database

na_to_space <- function(x) ifelse(is.na(x),"missing",x)
segment.db = segment.db %>% mutate_if(is.character, na_to_space) 
```
Cria-se a variável NOTA_FINAL, a qual contempla todas as notas (CN, CH, LC, MT e REDAÇÃO) e dá um peso de 20% para cada uma.
Define-se, assim, um modelo rfe (recursive feature elimination), o qual cria modelos com diferentes subsets dos dados, analisando as mudanças no erro de predição. O objetivo é realizar seleção de variáveis importantes na predição da nota do aluno.
```{r}
segment.db = segment.db %>% mutate(NOTA_FINAL = (0.2*NU_NOTA_CN + 0.2*NU_NOTA_CH + 0.2*NU_NOTA_LC + 0.2*NU_NOTA_MT + 0.2*NU_NOTA_REDACAO)) %>% select(-starts_with("NU_NOTA"))

# selecting stratified 10% of database to apply rfe model and detect important variables that predicts test result
sample_train = segment.db %>% sample_frac(0.1) %>% mutate_if(is.character, as.factor)
  
set.seed(7)
# define the control using a random forest selection function
control <- rfeControl(functions=rfFuncs, method="cv", number=5)
# run the RFE algorithm
results <- rfe(sample_train[,-128], sample_train[,128], rfeControl=control)
# summarize the results
print(results)
# list the chosen features
selected_var =  c(predictors(results)[1:16], "NOTA_FINAL")
# plot the results
plot(results, type=c("g", "o"))
```
Nota-se que o RMSE mais baixo é o selecionando 16 variáveis. Assim, filtra-se a base com as mesmas para análises mais profundas.
```{r}
segment.db.scaled = segment.db %>% select(selected_var)

# Ward Hierarchical Clustering
d <- dist(segment.db.scaled, method = "euclidean") # distance matrix
fit <- hclust(d, method="ward.D") 
plot(fit) # display dendogram

# draw dendogram with red borders around the 3 clusters 
rect.hclust(fit, k=3, border="red")

groups <- data.frame(CLUSTER = cutree(fit, k=3)) # cut tree into 3 clusters
```

```{r}
segment.db.clusters = segment.db %>% select(selected_var) 
segment.db.clusters = bind_cols(segment.db.clusters, groups)

segment.db.clusters.num = segment.db.clusters %>% select_if(is.numeric) %>% melt(id.vars = "CLUSTER") %>% group_by(variable, CLUSTER) %>% summarise(mean = mean(value, na.rm = TRUE))
segment.db.clusters.char = segment.db.clusters %>% melt(id.vars = c("CLUSTER")) %>% filter(!variable == "NOTA_FINAL")
segment.db.clusters.char$CLUSTER = as.character(segment.db.clusters.char$CLUSTER)

bars = segment.db.clusters.char %>% 
  ggplot(aes(value, group = CLUSTER, fill=CLUSTER)) +
  geom_bar(position = "fill") +
  scale_y_continuous(labels = scales::percent_format()) +
  facet_wrap(~variable, scales = "free") +
  labs(title = "Figura: Distribuição das variáveis mais importantes", subtitle = "por cluster", x = "níveis da variável", y = "percentual do nível")

segment.db.clusters.num
bars
```

O cluster 3 é o que possui nota média mais alta e verifica-se um perfil dentro desse cluster.
Na variável Q047, por exemplo, pergunta-se em que tipo de escola o aluno frequentou no ensino médio. O cluster 3 (azul), domina os dois últimos níveis da variável, as quais se relacionam a escolas privadas. A Q042 segue a mesma tendência: domínio nos níveis C e D: opções que envolvem escolas privadas durante o ensino fundamental. A Q006 (renda familiar) é outra evidência: quanto maior a renda da família, maior a quantidade de domínio do cluster 3. Pode-se afirmar, portanto, que altas notas estão ligadas a rendas elevadas (Q006), ensino em escolas privadas (Q042, Q047), o pai finalizou pós graduação (Q001), o objetivo de realizar a prova para obter uma bolsa de estudos é um dos fatores menos importantes (Q037), entre outros parâmetros.

Fica claro que, através dessa segmentação, políticas de incentivo a educação no viés público são importantes, visto que é o grupo que possui maior debilidade em questão de suporte acadêmico, o qual é a base para se obter uma nota geral mais elevada no exame. Notas mais baixas também estão vinculadas à instrução dos responsáveis pelo aluno, visto que os mesmos possuem menos desenvolvimento acadêmico, ocupação em cargos de não-destaque e menores condições financeiras.